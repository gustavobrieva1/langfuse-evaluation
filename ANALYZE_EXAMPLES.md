# Analyzing Sample Conversations - Quick Guide

## ğŸ¯ Goal

Before running full evaluation on all conversations, you should:
1. **Test the evaluation system** on 10 sample conversations
2. **Understand what the AI evaluators detect**
3. **Validate evaluation quality**
4. **Adjust if needed** before spending money on full analysis

---

## ğŸš€ Two Ways to Analyze Examples

### Option 1: Standalone Script (Quickest)

Run the standalone analysis script:

```bash
# If using virtual environment
source venv/bin/activate

# Run analysis
python3 analyze_sample_conversations.py
```

**What it does:**
- Loads 10 sample conversations
- Runs multi-agent evaluation
- Shows detailed results for each conversation
- Displays summary statistics
- Interactive (press Enter between conversations)

**Output:**
```
Quick Summary Table
Quality Report
Detailed examination of each conversation
  - User question
  - Conecta's response
  - AI evaluator findings
  - Hallucination evidence
  - Document relevance
  - Completeness analysis
```

**Cost:** ~$0.04 for 10 conversations

---

### Option 2: Jupyter Notebook (More Interactive)

Use the comprehensive notebook with new analysis section:

```bash
jupyter notebook notebooks/conecta_hallucination_analysis.ipynb
```

**New cells to add** (copy from `notebooks/example_analysis_cells.txt`):

1. **Import Analysis Helpers** - Visualization tools
2. **Select & Evaluate 10 Samples** - Run evaluation
3. **Quick Summary Table** - Overview of results
4. **Quality Report** - Metrics and interpretation
5. **Detailed Examination** - Each conversation in detail
6. **Problematic Cases** - Focus on issues
7. **Evaluation Quality Checklist** - Manual review guide

**To add the cells:**
1. Open the notebook
2. Find Cell 13 (after "Test on Single Conversation")
3. Insert new cells and copy code from `example_analysis_cells.txt`

---

## ğŸ“Š What You'll See

### Summary Table

```
session_id      hallucination  severity  grounding  doc_score  comp_score  unnecessary_clarif
00321044...     âœ…            none      100%       5/5        5/5         âœ…
a7b3c...        ğŸ”´            major     60%        3/5        2/5         ğŸ”´
```

**Read as:**
- ğŸ”´ = Issue detected
- âœ… = No issues
- Grounding = % claims supported by documents
- Doc score = Relevance of retrieved documents
- Comp score = Completeness of response

### Quality Report

```
ğŸ“Š Overall Statistics:
   Total evaluations: 10
   âœ… Successful: 10
   âŒ Failed: 0

ğŸ¯ Detection Metrics:
   Average confidence: 85.3%
   Detection rate: 30.0%
   Average claims per response: 4.2
   Average grounding ratio: 78.5%

ğŸ“ˆ Severity Distribution:
   âœ… NONE: 7
   ğŸŸ¡ MINOR: 2
   ğŸ”´ MAJOR: 1
   ğŸ”¥ CRITICAL: 0
```

### Detailed Conversation Analysis

For each conversation, you'll see:

**1. User Question**
```
ğŸ“ USER QUESTION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Como puedo cancelar una tarjeta de crÃ©dito?
```

**2. Conecta's Response**
```
ğŸ¤– CONECTA'S RESPONSE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Para cancelar tu tarjeta de crÃ©dito Davivienda...
[Full response]
```

**3. Documents Used** (optional)
```
ğŸ“š DOCUMENTS USED:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Documento 1234: CancelaciÃ³n de tarjetas
[Document content]
```

**4. Hallucination Detection** (CRITICAL)
```
ğŸš¨ HALLUCINATION DETECTION (CRITICAL)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”´ Hallucination Detected: True
ğŸ”´ Severity: MAJOR
   Type: fabrication
   Confidence: 87.5%

ğŸ“Š Claims Analysis:
   Total claims examined: 5
   âœ… Grounded in documents: 3 (60.0%)
   âŒ Hallucinated/Unsupported: 2

ğŸ’­ AI Evaluator's Assessment:
The response contains claims about cancellation fees that
are not mentioned in the source documents. Specifically...

ğŸ” HALLUCINATED CLAIMS (Evidence):
   Claim #1:
   ğŸ“Œ Statement: "La cancelaciÃ³n tiene un costo de $50,000"
   ğŸ“„ Document Support: NOT FOUND
   ğŸ’¡ Explanation: This fee is not mentioned in any of the
                   provided documents about card cancellation.
```

**5. Document Relevance**
```
ğŸ” DOCUMENT RELEVANCE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Score: [â–ˆâ–ˆâ–ˆâ–‘â–‘] 3/5
   Documents contain answer: âœ… Yes

   âš ï¸  Missing Information:
      â€¢ Specific cancellation procedures
      â€¢ Required documents
```

**6. Completeness Check**
```
âœ… COMPLETENESS CHECK
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Score: [â–ˆâ–ˆâ–‘â–‘â–‘] 2/5
   Used all relevant info: âŒ No
   ğŸ”´ UNNECESSARY CLARIFICATION DETECTED
      â†’ Conecta asked for clarification when answer
         was in documents!

   âš ï¸  Information NOT included in response:
      â€¢ Online cancellation option
      â€¢ Timeframe for cancellation
```

**7. Escalation Validation**
```
ğŸ¯ ESCALATION VALIDATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Actually escalated: âŒ No
   Escalation was appropriate: âŒ No
   Should have escalated: âŒ No

   ğŸ’­ Reason: The documents contain sufficient information
              to answer the question. No escalation needed.
```

**8. Secondary Verification** (if hallucination detected)
```
ğŸ”¬ SECONDARY VERIFICATION (Critical Finding)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Verified: âœ… Confirmed
   Adjusted severity: major
   Final recommendation: REJECT

   ğŸ’­ Verification explanation:
   The original finding is correct. The cancellation fee
   claim is indeed not supported by any documents.
```

---

## ğŸ¯ How to Use This Information

### 1. Validate Evaluations

For each conversation, ask yourself:
- âœ… **Is the hallucination detection correct?**
- âœ… **Are the severity levels appropriate?**
- âœ… **Does the completeness assessment make sense?**
- âœ… **Are document relevance scores accurate?**

### 2. Look for Patterns

```
Common issues to spot:
â–¡ Conecta frequently makes up information
â–¡ Documents often don't contain answers
â–¡ Conecta asks for unnecessary clarification
â–¡ Responses are incomplete
â–¡ Escalations are inappropriate
```

### 3. Adjust if Needed

**If evaluations are too strict:**
```python
# In notebook or config
config.temperature = 0.2  # Higher = more lenient
```

**If evaluations are too lenient:**
```python
config.temperature = 0.05  # Lower = more strict
```

**If specific prompts need tuning:**
```python
# Edit: src/utils/prompt_templates.py
# Adjust the prompts for each agent
```

### 4. Decide Next Steps

**Evaluations look good?**
â†’ Proceed to full batch evaluation

**Need adjustments?**
â†’ Tune prompts/config and re-run sample

**Want more examples?**
â†’ Change sample size or indices

---

## ğŸ’¡ Pro Tips

### Focus on Interesting Cases

The script automatically identifies:
- ğŸ”´ Hallucinations detected
- ğŸ”´ Unnecessary clarifications
- ğŸ”´ Low grounding (<80%)
- ğŸ”´ Poor document relevance (<3/5)

Review these first!

### Compare with Your Judgment

For a few conversations:
1. Read the user question
2. Read Conecta's response
3. Read the documents
4. Form your own opinion
5. Compare with AI evaluation
6. Assess agreement

### Check Edge Cases

Look for:
- Very short questions (vague)
- Very long responses (complex)
- Technical banking terminology
- Ambiguous requests

### Document Your Findings

Create a checklist:
```
âœ… Hallucination detection is accurate
âŒ Completeness scoring too strict
âœ… Document relevance makes sense
âš ï¸  Need to adjust severity threshold
```

---

## ğŸ“‹ Evaluation Quality Checklist

After reviewing 10 examples:

**Hallucination Detection:**
- [ ] Flagged hallucinations are actually incorrect
- [ ] No false positives (correct info marked as hallucination)
- [ ] No false negatives (missed hallucinations)
- [ ] Severity levels make sense

**Document Relevance:**
- [ ] Relevant documents scored high
- [ ] Irrelevant documents scored low
- [ ] "Has answer" flag is accurate

**Completeness:**
- [ ] Complete responses scored high
- [ ] Incomplete responses scored low
- [ ] "Unnecessary clarification" flag is accurate

**Overall Quality:**
- [ ] AI evaluations align with human judgment
- [ ] Confidence scores correlate with accuracy
- [ ] No systematic biases detected

---

## ğŸ› Troubleshooting

### "Model not found" error

The model name was fixed. If you still see this:
```bash
# Update the code
git pull
```

### Script hangs / takes too long

- Check your internet connection
- Verify API key is valid
- Reduce sample size to 5 conversations

### Evaluations seem random

- Lower temperature for consistency
- Use Pro model for all agents
- Check if documents are being loaded correctly

---

## ğŸ“ What to Learn

From this analysis, you should understand:

1. **How the AI evaluators work**
   - What they detect
   - How they reason
   - Their strengths and limitations

2. **Conecta's performance patterns**
   - Common hallucination types
   - Document retrieval quality
   - Response completeness

3. **System reliability**
   - False positive rate
   - False negative rate
   - Overall accuracy

4. **Next steps**
   - Whether to proceed to full analysis
   - What adjustments are needed
   - Expected results

---

## ğŸ“š Next Steps

**After analyzing examples:**

1. âœ… Review evaluation quality
2. âœ… Adjust prompts/config if needed
3. âœ… Re-run sample if necessary
4. ğŸš€ Proceed to full batch evaluation
5. ğŸ“Š Generate comprehensive report
6. ğŸ’¡ Create improvement recommendations

**Ready for full analysis?**
â†’ See main notebook or run full evaluation

**Need help?**
â†’ See README.md for complete documentation

---

**Happy analyzing! ğŸš€**
