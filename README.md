# Conecta AI Agent Hallucination Analysis System

## Multi-Agent Evaluation Pipeline for Banking AI Assistant

This system implements a sophisticated **Multi-Agent Specialist Pipeline** to analyze the performance of "Conecta", a banking AI assistant, with a primary focus on detecting hallucinations (made-up information).

---

## ğŸ—ï¸ Architecture

### **Option 2: Multi-Agent Specialist Pipeline** (Implemented)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Orchestrator                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚             â”‚
        â–¼            â–¼            â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent 1    â”‚ â”‚   Agent 2    â”‚ â”‚   Agent 3    â”‚ â”‚   Agent 4    â”‚
â”‚              â”‚ â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
â”‚ Document     â”‚ â”‚ Hallucinationâ”‚ â”‚ Completeness â”‚ â”‚ Escalation   â”‚
â”‚ Relevance    â”‚ â”‚ Detector â­  â”‚ â”‚ Checker      â”‚ â”‚ Validator    â”‚
â”‚              â”‚ â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
â”‚ Gemini Flash â”‚ â”‚ Gemini Pro   â”‚ â”‚ Gemini Flash â”‚ â”‚ Gemini Flash â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ If hallucination detected
                        â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Agent 5    â”‚
                 â”‚ Verification â”‚
                 â”‚ (Secondary)  â”‚
                 â”‚ Gemini Pro   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agents

1. **ğŸ” Document Relevance Agent** (Flash)
   - Checks if retrieved documents are relevant to the question
   - Fast evaluation using Gemini Flash

2. **ğŸš¨ Hallucination Detector** (Pro) - **CRITICAL**
   - Detects when Conecta makes up information
   - Identifies: Fabrication, Distortion, Information Mixing, Contradictions
   - Uses powerful Gemini Pro model for accuracy

3. **âœ… Completeness Checker** (Flash)
   - Validates if response uses all available document information
   - Detects unnecessary clarification requests

4. **ğŸ¯ Escalation Validator** (Flash)
   - Judges if escalation to human expert was appropriate
   - Identifies preventable escalations

5. **ğŸ”¬ Verification Agent** (Pro)
   - Secondary verification for critical findings
   - Reduces false positives in hallucination detection

---

## ğŸ“Š Data Pipeline

### Input Files (4 CSVs)

1. **df_merged_final_oct_v3.csv** (33K rows)
   - Main conversation data
   - User questions and Conecta responses
   - Escalation triggers

2. **df_merged_genesys (1).csv** (738 rows)
   - Expert escalation transcripts
   - Links via `fk_tbl_conversaciones_conecta2`

3. **1758819667267-lf-traces-export-cm38vdgjp005z3hq2htm5f0mx.csv** (975 rows)
   - Langfuse trace data
   - Document IDs used by Conecta
   - Execution metadata, costs

4. **base_conocimiento_ajustada_cargue_produccion_v2 (1).csv** (2.4K rows)
   - Knowledge base with Q&A pairs
   - Document content and keywords

### ETL Process

```python
# Step 1: Load all files
data = load_all_data(data_dir=".")

# Step 2: Process Langfuse JSON
analysis_df = merge_all_datasets(data)

# Step 3: Enrich with document content
enriched_df = enrich_with_documents(analysis_df, data['knowledge_base'])

# Step 4: Create conversation-level summary
conversation_df = create_conversation_summary(enriched_df)
```

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Set API key
export GEMINI_API_KEY='your-api-key-here'

# OR for Vertex AI
export VERTEX_PROJECT_ID='your-project-id'
```

### 2. Run Analysis

```bash
# Open Jupyter notebook
jupyter notebook notebooks/conecta_hallucination_analysis.ipynb
```

### 3. Configure Provider

**Option A: Gemini (Recommended for development)**

```python
from src.config import EvaluatorConfig, ProviderType, ModelType

config = EvaluatorConfig(
    provider=ProviderType.GEMINI,
    gemini_api_key=os.getenv('GEMINI_API_KEY'),
    hallucination_detector_model=ModelType.PRO
)
```

**Option B: Vertex AI (For production)**

```python
config = EvaluatorConfig(
    provider=ProviderType.VERTEX,
    vertex_project_id=os.getenv('VERTEX_PROJECT_ID'),
    hallucination_detector_model=ModelType.PRO
)
```

---

## ğŸ’° Cost Estimate

**Per 1,000 conversations:**
- Document Relevance (Flash): ~$0.50
- **Hallucination Detection (Pro)**: ~$2.00 â­
- Completeness (Flash): ~$0.50
- Escalation (Flash): ~$0.30
- Verification (Pro, 15% cases): ~$0.40
- **Total: ~$3.70**

---

## ğŸ“ Project Structure

```
langfuse_use/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ conecta_hallucination_analysis.ipynb    # Main analysis notebook
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                               # Configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ loader.py                           # Load CSV files
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ json_extractor.py                   # Parse Langfuse JSON
â”‚   â”‚   â”œâ”€â”€ merger.py                           # Merge datasets
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluators/
â”‚   â”‚   â”œâ”€â”€ base.py                             # Base classes
â”‚   â”‚   â”œâ”€â”€ factory.py                          # Provider factory
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_provider.py              # Gemini API
â”‚   â”‚   â”‚   â”œâ”€â”€ vertex_provider.py              # Vertex AI
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ agents/
â”‚   â”‚       â”œâ”€â”€ hallucination_detector.py       # â­ Critical agent
â”‚   â”‚       â”œâ”€â”€ document_relevance.py
â”‚   â”‚       â”œâ”€â”€ completeness_checker.py
â”‚   â”‚       â”œâ”€â”€ escalation_validator.py
â”‚   â”‚       â”œâ”€â”€ verification_agent.py
â”‚   â”‚       â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator.py                         # Agent coordination
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py                 # Prompt management
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Usage Examples

### Evaluate Single Conversation

```python
from src.orchestrator import EvaluationOrchestrator, ConversationData

# Initialize
orchestrator = EvaluationOrchestrator(config)

# Prepare data
conversation = ConversationData(
    session_id="session_123",
    user_question="Â¿CÃ³mo puedo abrir una cuenta?",
    ai_response="Para abrir una cuenta...",
    documents="Documento 1: Requisitos...",
    escalated=False
)

# Evaluate
result = orchestrator.evaluate_conversation(conversation)

# Check results
if result.hallucination['hallucination_detected']:
    print(f"âš ï¸ Hallucination detected: {result.hallucination['severity']}")
```

### Batch Evaluation

```python
# Prepare batch
conversations = [...]  # List of ConversationData

# Run batch
results = orchestrator.evaluate_batch(
    conversations,
    run_verification=True,
    max_workers=3
)

# Analyze
results_df = pd.DataFrame([r.to_dict() for r in results])
```

---

## ğŸ“Š Key Metrics

### Hallucination Detection

- **Hallucination Rate**: % of responses with made-up info
- **Severity**: None, Minor, Major, Critical
- **Types**: Fabrication, Distortion, Mixing, Contradiction
- **Grounding Ratio**: % of claims supported by documents

### Response Quality

- **Document Relevance Score**: 1-5 (Are docs relevant?)
- **Completeness Score**: 1-5 (Did Conecta use all info?)
- **Unnecessary Clarifications**: When answer was available

### Escalation Quality

- **Appropriate Escalations**: Should have gone to expert
- **Preventable Escalations**: Conecta had the answer

---

## ğŸ¯ Priority: Hallucination Detection

The system is optimized for detecting **hallucinations** (made-up information), which is the most critical failure mode:

### Why Critical?
- âŒ Incorrect information to customers
- âŒ Compliance violations
- âŒ Financial losses
- âŒ Reputation damage

### Detection Method
1. Extract all factual claims from Conecta's response
2. Search documents for supporting evidence
3. Flag claims without clear document support
4. Verify critical findings with secondary agent
5. Provide specific evidence and severity rating

---

## ğŸ”„ Extending the System

### Add New Agent

```python
from src.evaluators.base import BaseAgent, EvaluationResult

class MyCustomAgent(BaseAgent):
    def get_prompt(self, **kwargs) -> str:
        # Return formatted prompt
        pass

    def parse_response(self, response: dict) -> EvaluationResult:
        # Parse LLM response
        pass
```

### Switch Model for Agent

```python
config = EvaluatorConfig(
    # Use Pro for all agents
    document_relevance_model=ModelType.PRO,
    hallucination_detector_model=ModelType.PRO,
    completeness_checker_model=ModelType.PRO
)
```

---

## ğŸ“ Output Files

After running analysis:

1. **conecta_evaluation_results_TIMESTAMP.csv**
   - Full evaluation results for all conversations

2. **critical_hallucinations_TIMESTAMP.csv**
   - Only conversations with major/critical hallucinations

3. **evaluation_summary_TIMESTAMP.json**
   - Summary statistics and key metrics

4. **conecta_evaluation_results.png**
   - Visualization dashboard

---

## ğŸ› Troubleshooting

### API Key Issues

```bash
# Check if key is set
echo $GEMINI_API_KEY

# Set temporarily
export GEMINI_API_KEY='your-key'

# Set permanently (add to ~/.bashrc or ~/.zshrc)
echo 'export GEMINI_API_KEY="your-key"' >> ~/.bashrc
```

### Rate Limiting

If you hit rate limits, adjust config:

```python
config = EvaluatorConfig(
    requests_per_minute=30,  # Lower rate
    max_retries=5  # More retries
)
```

### Parallel Execution Issues

Disable parallel execution:

```python
config = EvaluatorConfig(
    parallel_agents=False  # Run sequentially
)
```

---

## ğŸ“š Dependencies

- **google-generativeai**: Gemini API
- **google-cloud-aiplatform**: Vertex AI (optional)
- **pandas**: Data manipulation
- **numpy**: Numerical operations
- **matplotlib, seaborn**: Visualization
- **jupyter**: Notebook interface

---

## ğŸ¤ Contributing

This is a custom analysis system for Conecta. To modify:

1. Update agents in `src/evaluators/agents/`
2. Modify prompts in `src/utils/prompt_templates.py`
3. Adjust ETL in `src/etl/`

---

## ğŸ“„ License

Internal use only - Bank Davivienda

---

## ğŸ¯ Next Steps

1. âœ… Run initial analysis on Langfuse data
2. ğŸ“Š Identify top hallucination patterns
3. ğŸ”§ Improve Conecta's grounding mechanism
4. ğŸ“ˆ Monitor hallucination rate over time
5. ğŸš€ Expand to full conversation dataset

---

**Built with â¤ï¸ for improving Conecta's reliability and trustworthiness**
